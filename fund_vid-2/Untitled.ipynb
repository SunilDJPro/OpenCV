{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2720fb-cc32-47f0-b3b0-51889c829259",
   "metadata": {},
   "source": [
    "## OpenCV Video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca61a91-49f2-4146-b002-df4448a8695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6065212-b9a4-4676-94e9-a6662a425009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply various transformations to the frame\n",
    "def transform_frame(frame):\n",
    "    # Convert the frame to HSV (Hue, Saturation, Value) color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply a color transformation by adjusting the Hue channel\n",
    "    # Here we shift the hue slightly towards blue\n",
    "    hsv_frame[:, :, 0] += 15  # Increase Hue by 15\n",
    "    \n",
    "    # Convert back to BGR for display\n",
    "    transformed_frame = cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Apply a Gaussian blur to the frame\n",
    "    blurred_frame = cv2.GaussianBlur(transformed_frame, (15, 15), 0)\n",
    "    \n",
    "    # Detect edges in the frame using the Canny edge detector\n",
    "    edge_frame = cv2.Canny(blurred_frame, threshold1=30, threshold2=150)\n",
    "    \n",
    "    return edge_frame #Change this to visualize each effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "009570cd-16e8-4914-852f-c9e0cabbaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Sample.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "068d9e44-0b56-487f-bc07-bf4990dd0008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Ends\n"
     ]
    }
   ],
   "source": [
    "frame_rate = 30  # Desired frame rate in frames per second\n",
    "delay = int(1000 / frame_rate)  # Convert frame rate to delay time in milliseconds\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if the frame was successfully read; if not, break the loop\n",
    "    if not ret:\n",
    "        print(\"Video Ends\")\n",
    "        break \n",
    "    \n",
    "    try:\n",
    "        # Process the frame using a defined transform_frame function\n",
    "        processed_frame = transform_frame(frame)  # Replace with your actual processing logic\n",
    "        \n",
    "        # Display the processed frame in a window named 'Processed Frame'\n",
    "        cv2.imshow('Processed Frame', processed_frame)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during frame transformation: {e}\")\n",
    "        break \n",
    "    \n",
    "    key = cv2.waitKey(delay) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47d0f1d1-04dd-4969-be53-8796cbc9b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a770f69-aece-491b-8c06-09109a6d7426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
